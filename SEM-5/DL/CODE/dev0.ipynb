{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/mithindev/Desktop/COLLEGE/SEM-5/DL/CODE/data/drion_training.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#path2labels=\"/media/mithun/New Volume/2021_pc/disc/code/drion_training.xlsx\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m path2labels\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path2data,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrion_training.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m labels_df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath2labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m labels_df\u001b[38;5;241m.\u001b[39mhead()\n\u001b[1;32m     25\u001b[0m labels_df\u001b[38;5;241m.\u001b[39mtail()\n",
      "File \u001b[0;32m~/Desktop/COLLEGE/SEM-5/DL/CODE/myenv/lib/python3.12/site-packages/pandas/io/excel/_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/COLLEGE/SEM-5/DL/CODE/myenv/lib/python3.12/site-packages/pandas/io/excel/_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1557\u001b[0m         )\n",
      "File \u001b[0;32m~/Desktop/COLLEGE/SEM-5/DL/CODE/myenv/lib/python3.12/site-packages/pandas/io/excel/_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/COLLEGE/SEM-5/DL/CODE/myenv/lib/python3.12/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/mithindev/Desktop/COLLEGE/SEM-5/DL/CODE/data/drion_training.xlsx'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import torchvision.transforms.functional as TF\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image, ImageDraw\n",
    "from torchvision import utils\n",
    "\n",
    "path2data=\"/Users/mithindev/Desktop/COLLEGE/SEM-5/DL/CODE/data\"\n",
    "path2train=\"/Users/mithindev/Desktop/COLLEGE/SEM-5/DL/CODE/data/train\"\n",
    "\n",
    "\n",
    "#path2labels=\"/media/mithun/New Volume/2021_pc/disc/code/drion_training.xlsx\"\n",
    "# path2labels=os.path.join(path2data,\"drion_training.xlsx\")\n",
    "# labels_df=pd.read_excel(path2labels)\n",
    "# labels_df.head()\n",
    "# labels_df.tail()\n",
    "# print(labels_df['label'].value_counts())\n",
    "# imgName=labels_df[\"imgName\"]\n",
    "\n",
    "\n",
    "\n",
    "# def load_img_label(labels_df,id_):   \n",
    "    # imgName=labels_df[\"imgName\"]\n",
    "    # fullPath2img=os.path.join(path2data,\"training_drion\",imgName[id_])\n",
    "    # img = Image.open(fullPath2img)\n",
    "    # x=labels_df[\"label\"][id_]\n",
    "    # label=x \n",
    "    # return img,label \n",
    "    \n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "def create_labels_dataframe(path2data, excel_path):\n",
    "    data = []\n",
    "    for category in ['cats', 'dogs']:\n",
    "        folder_path = os.path.join(path2data, category)\n",
    "        for img_name in os.listdir(folder_path):\n",
    "            if img_name.endswith('.jpg'):\n",
    "                img_path = os.path.join(folder_path, img_name)\n",
    "                label = 0 if category == 'cats' else 1  # Assign label: 0 for cats, 1 for dogs\n",
    "                data.append((img_path, label))\n",
    "    \n",
    "    labels_df = pd.DataFrame(data, columns=['img_path', 'label'])\n",
    "    labels_df.to_excel(excel_path, index=False)  # Save to Excel file\n",
    "    return labels_df\n",
    "\n",
    "def my_load_img_labels(excel_path, id_):\n",
    "    labels_df = pd.read_excel(excel_path)\n",
    "    img_path = labels_df[\"img_path\"].iloc[id_]\n",
    "    img = Image.open(img_path)\n",
    "    label = labels_df[\"label\"].iloc[id_]\n",
    "    return img, label\n",
    "\n",
    "class AMD_dataset(Dataset):\n",
    "      def __init__(self, path2data,transform):\n",
    "           path2labels=os.path.join(path2data,\"drion_training.xlsx\")\n",
    "           labels_df=pd.read_excel(path2labels)\n",
    "           self.labels = labels_df[[\"label\"]].values\n",
    "           self.imgName=labels_df[\"imgName\"]\n",
    "           self.ids=labels_df.index\n",
    "           self.fullPath2img=[0]*len(self.ids)\n",
    "           for id_ in self.ids:\n",
    "               self.fullPath2img[id_-1]=os.path.join(path2data,\"training_drion\",imgName[id_])\n",
    "           self.transform = transform\n",
    "                    \n",
    "           \n",
    "      def __len__(self):\n",
    "          return len(self.labels)\n",
    "      \n",
    "      def __getitem__(self, idx):\n",
    "          #image = Image.open(self.fullPath2img)\n",
    "          image = Image.open(self.fullPath2img[idx],mode=\"r\")\n",
    "          label= self.labels[idx]\n",
    "          #image = self.transform(image)\n",
    "          image,label = self.transform(image,label)\n",
    "          return image, self.labels[idx]\n",
    "     \n",
    "        \n",
    "def transformer(image, label):\n",
    "    image=TF.to_tensor(image)\n",
    "    return image, label\n",
    "\n",
    "amd_ds1=AMD_dataset(path2data,transformer)\n",
    "amd_ds2=AMD_dataset(path2data,transformer)\n",
    "print(len(amd_ds1))\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "sss = ShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "indices=range(len(amd_ds1))\n",
    "for train_index, val_index in sss.split(indices):\n",
    "    print(len(train_index))\n",
    "    print(\"-\"*10)\n",
    "    print(len(val_index))\n",
    "from torch.utils.data import Subset\n",
    "train_ds=Subset(amd_ds1,train_index)\n",
    "print(len(train_ds))\n",
    "val_ds=Subset(amd_ds2,val_index)\n",
    "print(len(val_ds))\n",
    "\n",
    "\n",
    "def show(img,label):\n",
    "    npimg = np.array(img)\n",
    "    npimg_tr=np.transpose(npimg, (1,2,0))\n",
    "    plt.imshow(npimg_tr)\n",
    "    #plt.imshow(np.asarray(img))\n",
    "    if label is not None:\n",
    "        x=label\n",
    "        plt.plot(x,'b+',markersize=30)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "for img,label in train_ds:\n",
    "    show(img,label)\n",
    "    break \n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "for img,label in val_ds:\n",
    "    show(img,label)\n",
    "    break  \n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "train_dl = DataLoader(train_ds, batch_size=5, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=3, shuffle=True)\n",
    "\n",
    "for img_b, label_b in train_dl:\n",
    "    print(img_b.shape,img_b.dtype)\n",
    "    print(label_b.shape)\n",
    "    break\n",
    "\n",
    "for img_b, label_b in val_dl:\n",
    "    print(img_b.shape,img_b.dtype)\n",
    "    #label_b=torch.stack(label_b,1)\n",
    "    label_b=label_b.type(torch.float32)\n",
    "    print(label_b.shape,label_b.dtype)\n",
    "    break\n",
    "\n",
    "for x,y in train_dl:\n",
    "    print(x.shape,y)\n",
    "    break\n",
    "for x, y in train_dl:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    \n",
    "def accuracy(labels, out):\n",
    "    return np.sum(out==labels)/float(len(labels))\n",
    "\n",
    "import torch.nn as nn          \n",
    "def findConv2dOutShape(H_in,W_in,conv,pool=2):# get conv arguments\n",
    "    kernel_size=conv.kernel_size\n",
    "    stride=conv.stride\n",
    "    padding=conv.padding\n",
    "    dilation=conv.dilation\n",
    "    H_out=np.floor((H_in+2*padding[0]-dilation[0]*(kernel_size[0]-1)-1)/stride[0]+1)\n",
    "    W_out=np.floor((W_in+2*padding[1]-dilation[1]*(kernel_size[1]-1)-1)/stride[1]+1)\n",
    "    if pool:\n",
    "       H_out/=pool\n",
    "       W_out/=pool\n",
    "    return int(H_out),int(W_out) \n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "class Net(nn.Module):\n",
    "      def __init__(self, params):\n",
    "          super(Net, self).__init__()\n",
    "          C_in,H_in,W_in=params[\"input_shape\"]\n",
    "          init_f=params[\"initial_filters\"]\n",
    "          num_fc1=params[\"num_fc1\"]\n",
    "          num_classes=params[\"num_classes\"]\n",
    "          self.dropout_rate=params[\"dropout_rate\"]\n",
    "          self.conv1 = nn.Conv2d(C_in, init_f, kernel_size=3)\n",
    "          h,w=findConv2dOutShape(H_in,W_in,self.conv1)\n",
    "          self.conv2 = nn.Conv2d(init_f, 2*init_f, kernel_size=3)\n",
    "          h,w=findConv2dOutShape(h,w,self.conv2)\n",
    "          self.conv3 = nn.Conv2d(2*init_f, 4*init_f, kernel_size=3)\n",
    "          h,w=findConv2dOutShape(h,w,self.conv3)\n",
    "          self.conv4 = nn.Conv2d(4*init_f, 8*init_f, kernel_size=3)\n",
    "          h,w=findConv2dOutShape(h,w,self.conv4)\n",
    "# compute the flatten size\n",
    "          self.num_flatten=h*w*8*init_f\n",
    "          self.fc1 = nn.Linear(self.num_flatten, num_fc1)\n",
    "          self.fc2 = nn.Linear(num_fc1, num_classes)\n",
    "      def forward(self, x):\n",
    "          x = F.relu(self.conv1(x))\n",
    "          x = F.max_pool2d(x, 2, 2)\n",
    "          x = F.relu(self.conv2(x))\n",
    "          x = F.max_pool2d(x, 2, 2)\n",
    "          x = F.relu(self.conv3(x))\n",
    "          x = F.max_pool2d(x, 2, 2)\n",
    "          x = F.relu(self.conv4(x))\n",
    "          x = F.max_pool2d(x, 2, 2)\n",
    "          x = x.view(-1, self.num_flatten)\n",
    "          x = F.relu(self.fc1(x))\n",
    "          x=F.dropout(x, self.dropout_rate, training= self.training)\n",
    "          x = self.fc2(x)\n",
    "          return F.log_softmax(x,dim=1)\n",
    "params_model={\n",
    "\"input_shape\": (3,70,70),\n",
    "\"initial_filters\": 8,\n",
    "\"num_fc1\": 100,\n",
    "\"dropout_rate\": 0.25,\n",
    "\"num_classes\": 2,\n",
    "}\n",
    "model = Net(params_model)\n",
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "   model=model.to(device)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# cnn_model = Net(params_model)\n",
    "# cnn_model = cnn_model.to(device)\n",
    "print(model)\n",
    "print(next(model.parameters()).device)\n",
    "\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 70, 70),device=device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Feb 29 09:29:05 2024\n",
    "\n",
    "@author: mithun\n",
    "\"\"\"\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import torchvision.transforms.functional as TF\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image, ImageDraw\n",
    "from torchvision import utils\n",
    "\n",
    "path2data=\"E:/Amrita_2024/DEEP LEARNING FOR SIGNAL & IMAGE PROCESSING/Python_neural network/\"\n",
    "path2train=\"E:/Amrita_2024/DEEP LEARNING FOR SIGNAL & IMAGE PROCESSING/Python_neural network/training_drion/\"\n",
    "#path2labels=\"/media/mithun/New Volume/2021_pc/disc/code/drion_training.xlsx\"\n",
    "path2labels=os.path.join(path2data,\"drion_training.xlsx\")\n",
    "labels_df=pd.read_excel(path2labels)\n",
    "labels_df.head()\n",
    "labels_df.tail()\n",
    "print(labels_df['label'].value_counts())\n",
    "imgName=labels_df[\"imgName\"]\n",
    "\n",
    "\n",
    "\n",
    "# def load_img_label(labels_df,id_):   \n",
    "#     imgName=labels_df[\"imgName\"]\n",
    "#     fullPath2img=os.path.join(path2data,\"training_drion\",imgName[id_])\n",
    "#     img = Image.open(fullPath2img)\n",
    "#     x=labels_df[\"label\"][id_]\n",
    "#     label=x \n",
    "#     return img,label \n",
    "# def show1(img,label):\n",
    "#     #npimg = img.numpy().transpose((1,2,0))\n",
    "#     npimg = img.numpy()\n",
    "#     npimg_tr=np.transpose(npimg, (1,2,0))\n",
    "#     plt.imshow(npimg_tr)\n",
    "\n",
    "\n",
    "class AMD_dataset(Dataset):\n",
    "      def __init__(self, path2data,transform):\n",
    "           path2labels=os.path.join(path2data,\"drion_training.xlsx\")\n",
    "           labels_df=pd.read_excel(path2labels)\n",
    "           self.labels = labels_df[[\"label\"]].values\n",
    "           self.imgName=labels_df[\"imgName\"]\n",
    "           self.ids=labels_df.index\n",
    "           self.fullPath2img=[0]*len(self.ids)\n",
    "           for id_ in self.ids:\n",
    "               self.fullPath2img[id_-1]=os.path.join(path2data,\"training_drion\",imgName[id_])\n",
    "           self.transform = transform\n",
    "                    \n",
    "           \n",
    "      def __len__(self):\n",
    "          return len(self.labels)\n",
    "      \n",
    "      def __getitem__(self, idx):\n",
    "          #image = Image.open(self.fullPath2img)\n",
    "          image = Image.open(self.fullPath2img[idx],mode=\"r\")\n",
    "          label= self.labels[idx]\n",
    "          #image = self.transform(image)\n",
    "          image,label = self.transform(image,label)\n",
    "          return image, self.labels[idx]\n",
    "     \n",
    "        \n",
    "def transformer(image, label):\n",
    "    image=TF.to_tensor(image)\n",
    "    return image, label\n",
    "\n",
    "amd_ds1=AMD_dataset(path2data,transformer)\n",
    "amd_ds2=AMD_dataset(path2data,transformer)\n",
    "print(len(amd_ds1))\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "sss = ShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "indices=range(len(amd_ds1))\n",
    "for train_index, val_index in sss.split(indices):\n",
    "    print(len(train_index))\n",
    "    print(\"-\"*10)\n",
    "    print(len(val_index))\n",
    "from torch.utils.data import Subset\n",
    "train_ds=Subset(amd_ds1,train_index)\n",
    "print(len(train_ds))\n",
    "val_ds=Subset(amd_ds2,val_index)\n",
    "print(len(val_ds))\n",
    "\n",
    "\n",
    "def show(img,label):\n",
    "    npimg = np.array(img)\n",
    "    npimg_tr=np.transpose(npimg, (1,2,0))\n",
    "    plt.imshow(npimg_tr)\n",
    "    #plt.imshow(np.asarray(img))\n",
    "    if label is not None:\n",
    "        x=label\n",
    "        plt.plot(x,'b+',markersize=30)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "for img,label in train_ds:\n",
    "    show(img,label)\n",
    "    break \n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "for img,label in val_ds:\n",
    "    show(img,label)\n",
    "    break  \n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "train_dl = DataLoader(train_ds, batch_size=5, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=3, shuffle=True)\n",
    "\n",
    "for img_b, label_b in train_dl:\n",
    "    print(img_b.shape,img_b.dtype)\n",
    "    print(label_b.shape)\n",
    "    break\n",
    "\n",
    "for img_b, label_b in val_dl:\n",
    "    print(img_b.shape,img_b.dtype)\n",
    "    #label_b=torch.stack(label_b,1)\n",
    "    label_b=label_b.type(torch.float32)\n",
    "    print(label_b.shape,label_b.dtype)\n",
    "    break\n",
    "\n",
    "for x,y in train_dl:\n",
    "    print(x.shape,y)\n",
    "    break\n",
    "for x, y in train_dl:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    \n",
    "def accuracy(labels, out):\n",
    "    return np.sum(out==labels)/float(len(labels))\n",
    "\n",
    "import torch.nn as nn          \n",
    "def findConv2dOutShape(H_in,W_in,conv,pool=2):# get conv arguments\n",
    "    kernel_size=conv.kernel_size\n",
    "    stride=conv.stride\n",
    "    padding=conv.padding\n",
    "    dilation=conv.dilation\n",
    "    H_out=np.floor((H_in+2*padding[0]-dilation[0]*(kernel_size[0]-1)-1)/stride[0]+1)\n",
    "    W_out=np.floor((W_in+2*padding[1]-dilation[1]*(kernel_size[1]-1)-1)/stride[1]+1)\n",
    "    if pool:\n",
    "       H_out/=pool\n",
    "       W_out/=pool\n",
    "    return int(H_out),int(W_out) \n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "class Net(nn.Module):\n",
    "      def __init__(self, params):\n",
    "          super(Net, self).__init__()\n",
    "          C_in,H_in,W_in=params[\"input_shape\"]\n",
    "          init_f=params[\"initial_filters\"]\n",
    "          num_fc1=params[\"num_fc1\"]\n",
    "          num_classes=params[\"num_classes\"]\n",
    "          self.dropout_rate=params[\"dropout_rate\"]\n",
    "          self.conv1 = nn.Conv2d(C_in, init_f, kernel_size=3)\n",
    "          h,w=findConv2dOutShape(H_in,W_in,self.conv1)\n",
    "          self.conv2 = nn.Conv2d(init_f, 2*init_f, kernel_size=3)\n",
    "          h,w=findConv2dOutShape(h,w,self.conv2)\n",
    "          self.conv3 = nn.Conv2d(2*init_f, 4*init_f, kernel_size=3)\n",
    "          h,w=findConv2dOutShape(h,w,self.conv3)\n",
    "          self.conv4 = nn.Conv2d(4*init_f, 8*init_f, kernel_size=3)\n",
    "          h,w=findConv2dOutShape(h,w,self.conv4)\n",
    "# compute the flatten size\n",
    "          self.num_flatten=h*w*8*init_f\n",
    "          self.fc1 = nn.Linear(self.num_flatten, num_fc1)\n",
    "          self.fc2 = nn.Linear(num_fc1, num_classes)\n",
    "      def forward(self, x):\n",
    "          x = F.relu(self.conv1(x))\n",
    "          x = F.max_pool2d(x, 2, 2)\n",
    "          x = F.relu(self.conv2(x))\n",
    "          x = F.max_pool2d(x, 2, 2)\n",
    "          x = F.relu(self.conv3(x))\n",
    "          x = F.max_pool2d(x, 2, 2)\n",
    "          x = F.relu(self.conv4(x))\n",
    "          x = F.max_pool2d(x, 2, 2)\n",
    "          x = x.view(-1, self.num_flatten)\n",
    "          x = F.relu(self.fc1(x))\n",
    "          x=F.dropout(x, self.dropout_rate, training= self.training)\n",
    "          x = self.fc2(x)\n",
    "          return F.log_softmax(x,dim=1)\n",
    "params_model={\n",
    "\"input_shape\": (3,70,70),\n",
    "\"initial_filters\": 8,\n",
    "\"num_fc1\": 100,\n",
    "\"dropout_rate\": 0.25,\n",
    "\"num_classes\": 2,\n",
    "}\n",
    "model = Net(params_model)\n",
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "   model=model.to(device)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# cnn_model = Net(params_model)\n",
    "# cnn_model = cnn_model.to(device)\n",
    "print(model)\n",
    "print(next(model.parameters()).device)\n",
    "\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 70, 70),device=device.type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
