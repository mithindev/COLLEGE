{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Jan 17 09:12:11 2024\n",
    "\n",
    "@author: mithun\n",
    "\"\"\"\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Jan 11 16:42:20 2024\n",
    "\n",
    "@author: mithun\n",
    "\"\"\"\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Dec 16 05:23:03 2022\n",
    "\n",
    "@author: mithun\n",
    "\"\"\"\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import torchvision.transforms.functional as TF\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image, ImageDraw\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import torchvision.transforms.functional as TF\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image, ImageDraw\n",
    "from torch import optim\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import torchvision.transforms.functional as TF\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image, ImageDraw\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import torchvision.transforms.functional as TF\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image, ImageDraw\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import torchvision.transforms.functional as TF\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image, ImageDraw\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import torchvision.transforms.functional as TF\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image, ImageDraw\n",
    "from torch import optim\n",
    "\n",
    "data_dir = \"E:/Amrita_2024/Improved_MSRNet/AMD1/\"\n",
    "mask_dir2=\"E:/Amrita_2024/Improved_MSRNet/vessel1/\"\n",
    "imgsList=[pp for pp in os.listdir(data_dir)]\n",
    "anntsList2=[pp for pp in os.listdir(mask_dir2)]\n",
    "print(\"number of images:\", len(imgsList))\n",
    "print(\"number of annotations:\", len(anntsList2))\n",
    "\n",
    "from albumentations import (HorizontalFlip,VerticalFlip,Compose,Resize)\n",
    "h,w=256,256\n",
    "\n",
    "#transform_train = Compose([ Resize(h,w),HorizontalFlip(p=0.5),VerticalFlip(p=0.5),])\n",
    "transform_train = Compose([ Resize(h,w)])\n",
    "transform_val = Resize(h,w)\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "#from torchvision.transforms.functional import to_pil_image\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "class fetal_dataset(Dataset):\n",
    "       def __init__(self, path2data,path2label2,num_class, transform=None):\n",
    "          imgsList=[pp for pp in os.listdir(path2data)]\n",
    "          anntsList2=[pp for pp in os.listdir(path2label2)]\n",
    "          self.path2imgs = [os.path.join(path2data, fn) for fn in imgsList]\n",
    "          self.path2annts2= [os.path.join(path2label2, fn) for fn in anntsList2]\n",
    "          self.transform = transform\n",
    "          self.num_class =num_class\n",
    "       def __len__(self):\n",
    "          return len(self.path2imgs)\n",
    " \n",
    "       def __getitem__(self, idx):\n",
    "          path2img = self.path2imgs[idx]\n",
    "          image = Image.open(path2img)\n",
    "          path2annt2 = self.path2annts2[idx]\n",
    "          mask2 = Image.open(path2annt2)\n",
    "          image= np.array(image)\n",
    "          mask2=np.asarray(mask2)\n",
    "          if self.transform: \n",
    "             augmented = self.transform(image=image, mask=mask2 )\n",
    "             image = augmented['image']\n",
    "             mask2 = augmented['mask']\n",
    "#             mask2=mask2.transpose(2,1,0)\n",
    "             mask2=mask2.astype(np.float32)\n",
    "          image= to_tensor(image)   \n",
    "          mask2=to_tensor(mask2)\n",
    "          mask2=mask2/torch.max(mask2)\n",
    "          \n",
    "          return image, mask2\n",
    "  \n",
    "\n",
    "fetal_ds1=fetal_dataset(data_dir,mask_dir2,1, transform=transform_train)\n",
    "fetal_ds2=fetal_dataset(data_dir,mask_dir2,1, transform=transform_val)\n",
    "\n",
    "img,msk1=fetal_ds1[0]\n",
    "#show_img_mask(img, mask)\n",
    "print(img.shape, img.type(),torch.max(img))\n",
    "print(msk1.shape, msk1.type(),torch.max(msk1))\n",
    "plt.figure(),plt.imshow(img[0])\n",
    "plt.figure(),plt.imshow(msk1[0])\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "sss = ShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "indices=range(len(fetal_ds1))\n",
    "for train_index, val_index in sss.split(indices):\n",
    "    print(len(train_index))\n",
    "    print(\"-\"*10)\n",
    "    print(len(val_index))\n",
    "\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "train_ds=Subset(fetal_ds1,train_index)\n",
    "print(len(train_ds))\n",
    "val_ds=Subset(fetal_ds2,val_index)\n",
    "print(len(val_ds))\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "train_dl = DataLoader(train_ds, batch_size=4, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=4, shuffle=False)\n",
    "for img_b, mask_b in train_dl:\n",
    "    print(img_b.shape,img_b.dtype)\n",
    "    print(mask_b.shape, mask_b.dtype)\n",
    "    break\n",
    "for img_b, mask_b in val_dl:\n",
    "    print(img_b.shape,img_b.dtype)\n",
    "    print(mask_b.shape, mask_b.dtype)\n",
    "    break\n",
    "#image_datasets = {'train': train_set, 'val': val_set}\n",
    "batch_size = 1\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "    'val': DataLoader(val_ds, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "}\n",
    "\n",
    "import torchvision.utils\n",
    "inputs, masks = next(iter(dataloaders['train']))\n",
    "\n",
    "print(inputs.shape, masks.shape)\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "                                  nn.Conv2d(ch_in, ch_out,\n",
    "                                            kernel_size=3, stride=1,\n",
    "                                            padding=1, bias=True),\n",
    "                                  nn.BatchNorm2d(ch_out),\n",
    "                                  nn.ReLU(inplace=True),\n",
    "                                  # nn.Conv2d(ch_out, ch_out,\n",
    "                                  #           kernel_size=3, stride=1,\n",
    "                                  #           padding=1, bias=True),\n",
    "                                  # nn.BatchNorm2d(ch_out),\n",
    "                                  # nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class UpConvBlock(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out):\n",
    "        super().__init__()\n",
    "        self.up = nn.Sequential(\n",
    "                                nn.Upsample(scale_factor=2),\n",
    "                                nn.Conv2d(ch_in, ch_out,\n",
    "                                         kernel_size=3,stride=1,\n",
    "                                         padding=1, bias=True),\n",
    "                                nn.BatchNorm2d(ch_out),\n",
    "                                nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x = self.up(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_classes=1, in_channel=1, out_channel=1):\n",
    "        super().__init__() \n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv1 = ConvBlock(ch_in=in_channel, ch_out=64)\n",
    "        self.conv2 = ConvBlock(ch_in=64, ch_out=128)\n",
    "        self.conv3 = ConvBlock(ch_in=128, ch_out=256)\n",
    "        self.conv4 = ConvBlock(ch_in=256, ch_out=512)\n",
    "        self.conv5 = ConvBlock(ch_in=512, ch_out=1024)\n",
    "        \n",
    "        self.up5 = UpConvBlock(ch_in=1024, ch_out=512)\n",
    "        self.upconv5 = ConvBlock(ch_in=1024, ch_out=512)\n",
    "        \n",
    "        self.up4 = UpConvBlock(ch_in=512, ch_out=256)\n",
    "        self.upconv4 = ConvBlock(ch_in=512, ch_out=256)\n",
    "        \n",
    "        self.up3 = UpConvBlock(ch_in=256, ch_out=128)\n",
    "        self.upconv3 = ConvBlock(ch_in=256, ch_out=128)\n",
    "        \n",
    "        self.up2 = UpConvBlock(ch_in=128, ch_out=64)\n",
    "        self.upconv2 = ConvBlock(ch_in=128, ch_out=64)\n",
    "        \n",
    "        self.conv_1x1 = nn.Conv2d(64, out_channel,\n",
    "                                  kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # encoder\n",
    "        x1 = self.conv1(x)\n",
    "        \n",
    "        x2 = self.maxpool(x1)\n",
    "        x2 = self.conv2(x2)\n",
    "        \n",
    "        x3 = self.maxpool(x2)\n",
    "        x3 = self.conv3(x3)\n",
    "        \n",
    "        x4 = self.maxpool(x3)\n",
    "        x4 = self.conv4(x4)\n",
    "        \n",
    "        x5 = self.maxpool(x4)\n",
    "        x5 = self.conv5(x5)\n",
    "        \n",
    "        # decoder + concat\n",
    "        d5 = self.up5(x5)\n",
    "        #\n",
    "        d5 = torch.concat((x4, d5), dim=1)\n",
    "        d5 = self.upconv5(d5)\n",
    "        \n",
    "        d4 = self.up4(d5)\n",
    "        d4 = torch.concat((x3, d4), dim=1)\n",
    "        d4 = self.upconv4(d4)\n",
    "        \n",
    "        d3 = self.up3(d4)\n",
    "        d3 = torch.concat((x2, d3), dim=1)\n",
    "        d3 = self.upconv3(d3)\n",
    "        \n",
    "        d2 = self.up2(d3)\n",
    "        d2 = torch.concat((x1, d2), dim=1)\n",
    "        d2 = self.upconv2(d2)\n",
    "        \n",
    "        d1 = self.conv_1x1(d2)\n",
    "        \n",
    "        return d1\n",
    "\n",
    "# model = AttentionUNet()\n",
    "# print(model)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "model = UNet(n_classes=1).to(device)\n",
    "model=model.to(device)\n",
    "print(model)\n",
    "output = torch.randn(1,1,256,256).to(device)\n",
    "output.shape\n",
    "torch.Size([1, 1, 256, 256])\n",
    "\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(1, 256, 256),device=device.type)\n",
    "\n",
    "\n",
    "def dice_loss(pred, target, smooth = 1e-5):\n",
    "    intersection = (pred * target).sum(dim=(2,3))\n",
    "    union= pred.sum(dim=(2,3)) + target.sum(dim=(2,3))\n",
    "    dice= 2.0 * (intersection + smooth) / (union+ smooth)\n",
    "    loss = 1.0 - dice\n",
    "    return loss.sum(), dice.sum()\n",
    "\n",
    "import torch.nn.functional as F\n",
    "def loss_func(pred, target):\n",
    "    bce = F.binary_cross_entropy_with_logits(pred, target,reduction='sum')\n",
    "    pred= torch.sigmoid(pred)\n",
    "    dlv, _ = dice_loss(pred, target)\n",
    "    loss = bce + dlv\n",
    "    return loss\n",
    "def metrics_batch(pred, target):\n",
    "    pred= torch.sigmoid(pred)\n",
    "    _, metric=dice_loss(pred, target)\n",
    "    return metric\n",
    "\n",
    "def loss_batch(loss_func, output, target, opt=None):\n",
    "    loss = loss_func(output, target)\n",
    "    _, metric_b=dice_loss(output, target)\n",
    "    if opt is not None:\n",
    "       opt.zero_grad()\n",
    "       loss.backward()\n",
    "       opt.step()\n",
    "    return loss.item(), metric_b\n",
    "from torch import optim\n",
    "opt = optim.Adam(model.parameters(), lr=3e-4)\n",
    "def get_lr(opt):\n",
    "    for param_group in opt.param_groups:\n",
    "        return param_group['lr']\n",
    "current_lr=get_lr(opt)\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "lr_scheduler = ReduceLROnPlateau(opt, mode='min',factor=0.5, patience=20,verbose=1)\n",
    "\n",
    "def loss_epoch(model,loss_func,dataset_dl,sanity_check=False,opt=None):\n",
    "    running_loss=0.0\n",
    "    running_metric=0.0\n",
    "    len_data=len(dataset_dl.dataset)\n",
    "    for xb, yb in dataset_dl:\n",
    "        xb=xb.type(torch.float32).to(device)\n",
    "        yb=yb.type(torch.float32).to(device)\n",
    "        output=model(xb)\n",
    "        loss_b, metric_b=loss_batch(loss_func, output, yb, opt)\n",
    "        running_loss += loss_b\n",
    "        if metric_b is not None:\n",
    "           running_metric+=metric_b\n",
    "        if sanity_check is True:\n",
    "           break\n",
    "    loss=running_loss/float(len_data)\n",
    "    metric=running_metric/float(len_data)\n",
    "    return loss, metric\n",
    "import time\n",
    "import copy\n",
    "def train_val(model, params):\n",
    "    num_epochs=params[\"num_epochs\"]\n",
    "    loss_func=params[\"loss_func\"]\n",
    "    opt=params[\"optimizer\"]\n",
    "    train_dl=params[\"train_dl\"]\n",
    "    val_dl=params[\"val_dl\"]\n",
    "    sanity_check=params[\"sanity_check\"]\n",
    "    lr_scheduler=params[\"lr_scheduler\"]\n",
    "    path2weights=params[\"path2weights\"]\n",
    "    loss_history={\"train\": [],\"val\": []}\n",
    "    metric_history={\"train\": [],\"val\": []}\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss=float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        current_lr=get_lr(opt)\n",
    "        print('Epoch {}/{}, current lr={}'.format(epoch, num_epochs- 1, current_lr))\n",
    "        since = time.time()\n",
    "        model.train() \n",
    "        train_loss,train_metric=loss_epoch(model,loss_func,train_dl,sanity_check,opt)\n",
    "        loss_history[\"train\"].append(train_loss)\n",
    "        metric_history[\"train\"].append(train_metric.item())\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "             val_loss,val_metric=loss_epoch(model,loss_func,val_dl,sanity_check)\n",
    "        loss_history[\"val\"].append(val_loss)\n",
    "        metric_history[\"val\"].append(val_metric.item())\n",
    "        if val_loss < best_loss:\n",
    "           best_loss = val_loss\n",
    "           best_model_wts = copy.deepcopy(model.state_dict())\n",
    "           torch.save(model.state_dict(), path2weights)\n",
    "           print(\"Copied best model weights!\")\n",
    "        lr_scheduler.step(val_loss)\n",
    "        #if current_lr == get_lr(opt):\n",
    "        print(\"Loading best model weights!\")\n",
    "        model.load_state_dict(best_model_wts)\n",
    "        print(\"train loss: %.6f, dice: %.2f\"%(train_loss,100*train_metric))\n",
    "        print(\"val loss: %.6f, dice: %.2f\"%(val_loss,100*val_metric))\n",
    "        print(\"-\"*10)\n",
    "        time_elapsed = time.time() - since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    return model, loss_history, metric_history\n",
    "\n",
    "#path2models= \"/media/mithun/BA423E4C423E0E1F/1PHD_NITP/2020/Glucoma_Research_Python/New_research/\"\n",
    "path2models= \"E:/Amrita_2024/Attention/\"\n",
    "if not os.path.exists(path2models):\n",
    "   os.mkdir(path2models)\n",
    "params_train={\n",
    "\"num_epochs\":2,\n",
    "\"optimizer\": opt,\n",
    "\"loss_func\": loss_func,\n",
    "\"train_dl\": train_dl,\n",
    "\"val_dl\": val_dl,\n",
    "\"sanity_check\": False,\n",
    "\"lr_scheduler\": lr_scheduler,\n",
    "\"path2weights\": path2models+\"weights_vessel_attn.pt\",\n",
    "}\n",
    "model,loss_hist,metric_hist=train_val(model,params_train)\n",
    "num_epochs=params_train[\"num_epochs\"]\n",
    "plt.title(\"Train-Val Loss\")\n",
    "plt.plot(range(1,num_epochs+1),loss_hist[\"train\"],label=\"train\")\n",
    "plt.plot(range(1,num_epochs+1),loss_hist[\"val\"],label=\"val\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.title(\"Train-Val Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),metric_hist[\"train\"],label=\"train\")\n",
    "plt.plot(range(1,num_epochs+1),metric_hist[\"val\"],label=\"val\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.legend()\n",
    "plt.show()    \n",
    "\n",
    "test_dataset = \"E:/Amrita_2024/Improved_MSRNet/new_test_gray/\"\n",
    "\n",
    "mask_dir_test_2=\"E:/Amrita_2024/Improved_MSRNet/new_test_mask/\"\n",
    "\n",
    "test_fetal_ds1=fetal_dataset(test_dataset,mask_dir_test_2,1, transform=transform_val)\n",
    "test_img,test_msk1=test_fetal_ds1[0]\n",
    "\n",
    "#show_img_mask(img, mask)\n",
    "print(test_img.shape, test_img.type(),torch.max(test_img))\n",
    "print(test_msk1.shape, test_msk1.type(),torch.max(test_msk1))\n",
    "\n",
    "test_loader = DataLoader(test_fetal_ds1, batch_size=1, shuffle=True)\n",
    "#inputs, masks = next(iter(test_loader))\n",
    "\n",
    "#print(inputs.shape, masks.shape)\n",
    "\n",
    "def reverse_transform(inp):\n",
    "    inp = inp.numpy().transpose((2, 1, 0))\n",
    "    #mean = np.array([0.485, 0.456, 0.406])\n",
    "    #std = np.array([0.229, 0.224, 0.225])\n",
    "    #inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    inp = (inp * 255).astype(np.uint8)\n",
    "\n",
    "    return inp\n",
    "\n",
    "inputs, labels = next(iter(test_loader))\n",
    "plt.figure()\n",
    "#plt.imshow(reverse_transform(inputs))\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "print(inputs.shape, labels.shape)\n",
    "#\n",
    "#\n",
    "## Predict\n",
    "pred = model(inputs)\n",
    "## The loss functions include the sigmoid function.\n",
    "pred = torch.sigmoid(pred)\n",
    "pred = pred.data.cpu().numpy()\n",
    "print(pred.shape)\n",
    "pred=np.squeeze(pred)\n",
    "print(pred.shape)\n",
    "print(pred)\n",
    "plt.figure()\n",
    "plt.imshow(pred)\n",
    "plt.figure()\n",
    "plt.imshow(pred,cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
