{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)>\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error downloading train-images-idx3-ubyte.gz",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 25\u001b[0m\n\u001b[1;32m     19\u001b[0m transform_image \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m     20\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m     21\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize((\u001b[38;5;241m0.5\u001b[39m,), (\u001b[38;5;241m0.5\u001b[39m,)),\n\u001b[1;32m     22\u001b[0m ])\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Dataset and DataLoader\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMNIST\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Display one batch shape\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/COLLEGE/SEM-5/DL/CODE/venv/lib/python3.12/site-packages/torchvision/datasets/mnist.py:100\u001b[0m, in \u001b[0;36mMNIST.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_exists():\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/COLLEGE/SEM-5/DL/CODE/venv/lib/python3.12/site-packages/torchvision/datasets/mnist.py:196\u001b[0m, in \u001b[0;36mMNIST.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError downloading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error downloading train-images-idx3-ubyte.gz"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torchsummary import summary\n",
    "\n",
    "# Hyperparameters\n",
    "number_epochs = 20\n",
    "batch_size = 128\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Transformations\n",
    "transform_image = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "# Dataset and DataLoader\n",
    "dataset = datasets.MNIST('./data', download=True, train=True, transform=transform_image)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Display one batch shape\n",
    "dataiter = iter(data_loader)\n",
    "images, labels = next(dataiter)\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "# Define the Autoencoder model\n",
    "class AutoencoderModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoencoderModel, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12, 3)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 28 * 28),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = AutoencoderModel()\n",
    "\n",
    "# Model summary\n",
    "summary(model, input_size=(1, 28 * 28))\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "# Helper function to convert tensor to image\n",
    "def to_image(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(number_epochs):\n",
    "    running_loss = 0.0\n",
    "    for data in data_loader:\n",
    "        image, _ = data\n",
    "        image = image.view(image.shape[0], -1)\n",
    "        image = Variable(image)\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(image)\n",
    "        loss = criterion(output, image)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print loss for the epoch\n",
    "    print(f\"Epoch {epoch + 1}/{number_epochs} - Training loss: {running_loss/len(data_loader):.4f}\")\n",
    "\n",
    "    # Save images every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        pic = to_image(output.cpu().data)\n",
    "        os.makedirs('output', exist_ok=True)\n",
    "        save_image(pic, f'output/image_{epoch + 1}.png')\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), './sim_autoencoder.pth')\n",
    "\n",
    "# Display the last image\n",
    "plt.imshow(pic[pic.shape[0]-1].numpy().squeeze(), cmap='gray_r')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "number_epochs = 10\n",
    "batch_size = 128\n",
    "learning_rate = 1e-4\n",
    "\n",
    "transform_image = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "dataset = datasets.MNIST('./data', download=True, train=True, transform=transform_image)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size,shuffle=True)\n",
    "\n",
    "\n",
    "dataiter = iter(data_loader)\n",
    "images, labels = next(dataiter)\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "\n",
    "class VariationalAutoEncoder(nn.Module):\n",
    "      def __init__(self):\n",
    "          super(VariationalAutoEncoder, self).__init__()\n",
    "          self.fc1 = nn.Linear(784, 400)\n",
    "          self.fc21 = nn.Linear(400, 20)\n",
    "          self.fc22 = nn.Linear(400, 20)\n",
    "          self.fc3 = nn.Linear(20, 400)\n",
    "          self.fc4 = nn.Linear(400, 784)\n",
    "      def encode_function(self, x):\n",
    "          h1 = F.relu(self.fc1(x))\n",
    "          return self.fc21(h1), self.fc22(h1)\n",
    "      def reparametrize(self, mu, logvar):\n",
    "          std = logvar.mul(0.5).exp_()\n",
    "          if torch.cuda.is_available():\n",
    "             eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "          else:\n",
    "              eps = torch.FloatTensor(std.size()).normal_()\n",
    "\n",
    "          eps = Variable(eps)\n",
    "          return eps.mul(std).add_(mu)\n",
    "      def decode_function(self, z):\n",
    "          h3 = F.relu(self.fc3(z))\n",
    "          return torch.sigmoid(self.fc4(h3))\n",
    "      def forward(self, x):\n",
    "          mu, logvar = self.encode_function(x)\n",
    "          z = self.reparametrize(mu, logvar)\n",
    "          return self.decode_function(z), mu, logvar\n",
    "\n",
    "model = VariationalAutoEncoder()\n",
    "\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(1, 28* 28)) \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,\n",
    "weight_decay=1e-5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def loss_function(reconstruction_x, x, mu, latent_log_variance):\n",
    "     #BCE = reconstruction_function(reconstruction_x, x)\n",
    "     BCE = criterion(reconstruction_x, x)\n",
    "# KL loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "     KLD_aspect =mu.pow(2).add_(latent_log_variance.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "     KLD = torch.sum(KLD_aspect).mul_(-0.5)\n",
    "     return BCE + KLD\n",
    "\n",
    "\n",
    "def to_image(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x\n",
    "\n",
    "\n",
    "for epoch in range(number_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(data_loader):\n",
    "        img, _ = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        img = Variable(img)\n",
    "        if torch.cuda.is_available():\n",
    "           img = img.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(img)\n",
    "        loss = loss_function(recon_batch, img, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "           print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch,\n",
    "                batch_idx * len(img),len(data_loader.dataset), 100. * batch_idx /len(data_loader),\n",
    "                train_loss / len(img)))\n",
    "           print('Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss /\n",
    "                  len(data_loader.dataset)))\n",
    "        if epoch % 10 == 0:\n",
    "           save = to_image(recon_batch.cpu().data)\n",
    "           save_image(save, 'E:/Amrita_2024/DEEP LEARNING FOR SIGNAL & IMAGE PROCESSING/Python_neural network/image_{}.png'.format(epoch))\n",
    "torch.save(model.state_dict(), './sim_autoencoder.pth')\n",
    "\n",
    "plt.imshow(save[save.shape[0]-1].numpy().squeeze(), cmap='gray_r');\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
