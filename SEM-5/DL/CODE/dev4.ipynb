{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# Paths\n",
    "path2train = \"data/train\"\n",
    "excel_path = os.path.join(path2train, \"image_labels.xlsx\")\n",
    "\n",
    "# Function to create labels DataFrame and save to Excel\n",
    "def create_labels_dataframe(path2train, excel_path):\n",
    "    data = []\n",
    "    index = 0\n",
    "    for img_name in os.listdir(path2train):\n",
    "        if img_name.endswith('.jpg'):\n",
    "            img_path = os.path.join(path2train, img_name)\n",
    "            img = Image.open(img_path)\n",
    "            img = img.resize((224, 224))  # Resize image to (224, 224)\n",
    "            img.save(img_path)  # Save resized image, overwriting the original\n",
    "            \n",
    "            label = 0 if 'cat' in img_name else 1  # Assign label: 0 for cats, 1 for dogs\n",
    "            data.append((index, img_name, label))\n",
    "            index += 1\n",
    "    \n",
    "    labels_df = pd.DataFrame(data, columns=['index', 'imgName', 'label'])\n",
    "    labels_df.to_excel(excel_path, index=False)  # Save to Excel file\n",
    "    return labels_df\n",
    "\n",
    "# Create labels dataframe\n",
    "labels_df = create_labels_dataframe(path2train, excel_path)\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "\n",
    "# Dataset class\n",
    "class AMD_dataset(Dataset):\n",
    "    def __init__(self, path2data, transform=None, img_size=(224, 224)):\n",
    "        self.path2labels = os.path.join(path2data, \"image_labels.xlsx\")\n",
    "        self.labels_df = pd.read_excel(self.path2labels)\n",
    "        self.labels = self.labels_df[\"label\"].values\n",
    "        self.img_names = self.labels_df[\"imgName\"]\n",
    "        self.ids = self.labels_df.index\n",
    "        self.transform = transform\n",
    "        self.img_size = img_size\n",
    "        self.path2train = path2data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_names[idx]\n",
    "        img_path = os.path.join(self.path2train, img_name)\n",
    "        image = Image.open(img_path).resize(self.img_size)  # Resize image\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "def transformer(image):\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "    image = TF.to_tensor(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "# Create dataset instances\n",
    "amd_ds = AMD_dataset(path2train, transformer)\n",
    "print(len(amd_ds))\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "sss = ShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "indices = range(len(amd_ds))\n",
    "for train_index, val_index in sss.split(indices):\n",
    "    print(len(train_index))\n",
    "    print(\"-\" * 10)\n",
    "    print(len(val_index))\n",
    "\n",
    "# Create training and validation subsets\n",
    "train_ds = Subset(amd_ds, train_index)\n",
    "val_ds = Subset(amd_ds, val_index)\n",
    "\n",
    "print(len(train_ds))\n",
    "print(len(val_ds))\n",
    "\n",
    "# DataLoader\n",
    "train_dl = DataLoader(train_ds, batch_size=5, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=3, shuffle=True)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "\n",
    "# CNN Model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(Net, self).__init__()\n",
    "        C_in, H_in, W_in = params[\"input_shape\"]\n",
    "        init_f = params[\"initial_filters\"]\n",
    "        num_fc1 = params[\"num_fc1\"]\n",
    "        num_classes = params[\"num_classes\"]\n",
    "        self.dropout_rate = params[\"dropout_rate\"]\n",
    "        self.conv1 = nn.Conv2d(C_in, init_f, kernel_size=3)\n",
    "        h, w = self.findConv2dOutShape(H_in, W_in, self.conv1)\n",
    "        self.conv2 = nn.Conv2d(init_f, 2 * init_f, kernel_size=3)\n",
    "        h, w = self.findConv2dOutShape(h, w, self.conv2)\n",
    "        self.conv3 = nn.Conv2d(2 * init_f, 4 * init_f, kernel_size=3)\n",
    "        h, w = self.findConv2dOutShape(h, w, self.conv3)\n",
    "        self.conv4 = nn.Conv2d(4 * init_f, 8 * init_f, kernel_size=3)\n",
    "        h, w = self.findConv2dOutShape(h, w, self.conv4)\n",
    "        # compute the flatten size\n",
    "        self.num_flatten = h * w * 8 * init_f\n",
    "        self.fc1 = nn.Linear(self.num_flatten, num_fc1)\n",
    "        self.fc2 = nn.Linear(num_fc1, num_classes)\n",
    "\n",
    "    def findConv2dOutShape(self, H_in, W_in, conv, pool=2):  # get conv arguments\n",
    "        kernel_size = conv.kernel_size\n",
    "        stride = conv.stride\n",
    "        padding = conv.padding\n",
    "        dilation = conv.dilation\n",
    "        H_out = np.floor((H_in + 2 * padding[0] - dilation[0] * (kernel_size[0] - 1) - 1) / stride[0] + 1)\n",
    "        W_out = np.floor((W_in + 2 * padding[1] - dilation[1] * (kernel_size[1] - 1) - 1) / stride[1] + 1)\n",
    "        if pool:\n",
    "            H_out /= pool\n",
    "            W_out /= pool\n",
    "        return int(H_out), int(W_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, self.num_flatten)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, self.dropout_rate, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Model parameters\n",
    "params_model = {\n",
    "    \"input_shape\": (3, 224, 224),\n",
    "    \"initial_filters\": 8,\n",
    "    \"num_fc1\": 100,\n",
    "    \"dropout_rate\": 0.25,\n",
    "    \"num_classes\": 2,\n",
    "}\n",
    "\n",
    "model = Net(params_model)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "print(next(model.parameters()).device)\n",
    "\n",
    "summary(model, input_size=(3, 224, 224), device=device.type)\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Training and validation loops\n",
    "def train_model(model, train_dl, val_dl, device, num_epochs=10, lr=0.001):\n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for images, labels in train_dl:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = running_loss / len(train_dl)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}\")\n",
    "        \n",
    "        # Validate the model\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        val_running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_dl:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_running_loss += loss.item()\n",
    "                \n",
    "                # Calculate accuracy\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        avg_val_loss = val_running_loss / len(val_dl)\n",
    "        val_accuracy = 100 * correct / total\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "    \n",
    "    print(\"Training complete\")\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_dl, val_dl, device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
