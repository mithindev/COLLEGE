{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    bird    cat    dog\n",
      "0  False   True  False\n",
      "1  False  False   True\n",
      "2   True  False  False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Input categories\n",
    "categories = ['cat', 'dog', 'bird']\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'Category': categories})\n",
    "\n",
    "# Perform one-hot encoding\n",
    "one_hot_encoded = pd.get_dummies(df['Category'])\n",
    "\n",
    "# Output the one-hot encoded DataFrame\n",
    "print(one_hot_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigrams: [('I',), ('love',), ('natural',), ('language',), ('processing',)]\n",
      "Bigrams: [('I', 'love'), ('love', 'natural'), ('natural', 'language'), ('language', 'processing')]\n",
      "Trigrams: [('I', 'love', 'natural'), ('love', 'natural', 'language'), ('natural', 'language', 'processing')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "\n",
    "# Input sentence\n",
    "sentence = \"I love natural language processing\"\n",
    "\n",
    "# Tokenize the sentence\n",
    "tokens = sentence.split()\n",
    "\n",
    "# Generate unigrams, bigrams, and trigrams\n",
    "unigrams = list(ngrams(tokens, 1))\n",
    "bigrams = list(ngrams(tokens, 2))\n",
    "trigrams = list(ngrams(tokens, 3))\n",
    "\n",
    "# Display the n-grams\n",
    "print(\"Unigrams:\", unigrams)\n",
    "print(\"Bigrams:\", bigrams)\n",
    "print(\"Trigrams:\", trigrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unigrams: [('I',), ('love',), ('natural',), ('language',), ('processing',)]\n",
    "# Bigrams: [('I', 'love'), ('love', 'natural'), ('natural', 'language'), ('language', 'processing')]\n",
    "# Trigrams: [('I', 'love', 'natural'), ('love', 'natural', 'language'), ('natural', 'language', 'processing')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words (BoW) Vectorization from Scratch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['amazing', 'and', 'data', 'i', 'is', 'language', 'love', 'natural', 'processing', 'programming', 'science']\n",
      "BoW Matrix:\n",
      "[[0 0 0 1 0 1 1 1 1 0 0]\n",
      " [1 0 0 0 1 1 0 1 1 0 0]\n",
      " [0 1 1 1 0 0 1 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def bow_vectorizer(corpus):\n",
    "    \"\"\"\n",
    "    Implements Bag of Words (BoW) vectorization from scratch.\n",
    "\n",
    "    :param corpus: List of sentences (documents) as strings\n",
    "    :return: Vocabulary, BoW matrix\n",
    "    \"\"\"\n",
    "    # Tokenize and create a vocabulary\n",
    "    tokenized_corpus = [sentence.lower().split() for sentence in corpus]\n",
    "    vocabulary = sorted(set(word for sentence in tokenized_corpus for word in sentence))\n",
    "\n",
    "    # Create BoW matrix\n",
    "    bow_matrix = np.zeros((len(corpus), len(vocabulary)), dtype=int)\n",
    "    for i, sentence in enumerate(tokenized_corpus):\n",
    "        word_count = Counter(sentence)\n",
    "        for j, word in enumerate(vocabulary):\n",
    "            bow_matrix[i, j] = word_count[word]\n",
    "\n",
    "    return vocabulary, bow_matrix\n",
    "\n",
    "# Example corpus\n",
    "corpus = [\n",
    "    \"I love natural language processing\",\n",
    "    \"Natural language processing is amazing\",\n",
    "    \"I love programming and data science\"\n",
    "]\n",
    "\n",
    "vocabulary, bow_matrix = bow_vectorizer(corpus)\n",
    "\n",
    "# Display the results\n",
    "print(\"Vocabulary:\", vocabulary)\n",
    "print(\"BoW Matrix:\")\n",
    "print(bow_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing TF-IDF Matrix Using Scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names: ['amazing' 'and' 'data' 'is' 'language' 'love' 'natural' 'processing'\n",
      " 'programming' 'science']\n",
      "TF-IDF Matrix:\n",
      "[[0.         0.         0.         0.         0.5        0.5\n",
      "  0.5        0.5        0.         0.        ]\n",
      " [0.51741994 0.         0.         0.51741994 0.3935112  0.\n",
      "  0.3935112  0.3935112  0.         0.        ]\n",
      " [0.         0.46735098 0.46735098 0.         0.         0.35543247\n",
      "  0.         0.         0.46735098 0.46735098]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Example corpus\n",
    "corpus = [\n",
    "    \"I love natural language processing\",\n",
    "    \"Natural language processing is amazing\",\n",
    "    \"I love programming and data science\"\n",
    "]\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Compute the TF-IDF matrix\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Extract feature names (vocabulary)\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert TF-IDF matrix to array\n",
    "tfidf_array = tfidf_matrix.toarray()\n",
    "\n",
    "# Display the results\n",
    "print(\"Feature Names:\", feature_names)\n",
    "print(\"TF-IDF Matrix:\")\n",
    "print(tfidf_array)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
